"""
data_processing.py
------------------

This module cleans and aggregates taxi trip data.  It reads a CSV file
generated by the ingestion step, drops invalid records, derives a trip
duration column and produces two outputs:

1. A cleaned CSV with the same columns as the input (plus the new
   ``trip_duration_minutes``) stored in ``data/processed/cleaned_trips.csv``.
2. A summary CSV with aggregated metrics by pickup date and vendor ID
   stored in ``data/processed/trip_summary.csv``.

The script prefers to use pandas for convenience but will fall back to
pure Python if pandas is unavailable.  Aggregated metrics include the
number of trips, average passenger count, average trip distance, total
fare amount and average trip duration per group.

Usage:

.. code-block:: bash

   python src/data_processing.py --input data/raw/yellow_tripdata_2025-01.csv

"""

import argparse
import csv
import datetime
import os
from collections import defaultdict
from typing import Dict, Tuple


def try_import_pandas():
    try:
        import pandas as pd  # type: ignore
        return pd
    except ImportError:
        return None


def process_with_pandas(input_csv: str, cleaned_csv: str, summary_csv: str) -> None:
    import pandas as pd  # type: ignore
    df = pd.read_csv(
        input_csv,
        parse_dates=["tpep_pickup_datetime", "tpep_dropoff_datetime"],
    )
    # Ensure datetime columns are properly converted even if pandas fails to
    # infer them (for example if the CSV contains invalid ISO formats).
    df["tpep_pickup_datetime"] = pd.to_datetime(df["tpep_pickup_datetime"], errors="coerce")
    df["tpep_dropoff_datetime"] = pd.to_datetime(df["tpep_dropoff_datetime"], errors="coerce")
    # Drop rows with obvious invalid values
    df = df.dropna(subset=[
        "tpep_pickup_datetime",
        "tpep_dropoff_datetime",
        "passenger_count",
        "trip_distance",
        "fare_amount",
        "total_amount",
    ])
    df = df[df["trip_distance"] > 0]
    df = df[df["fare_amount"] >= 0]
    # Derive trip duration in minutes
    df["trip_duration_minutes"] = (df["tpep_dropoff_datetime"] - df["tpep_pickup_datetime"]).dt.total_seconds() / 60.0
    df.to_csv(cleaned_csv, index=False)
    # Compute daily & vendor summary
    df["pickup_date"] = df["tpep_pickup_datetime"].dt.date
    summary = df.groupby(["pickup_date", "vendor_id"]).agg(
        trips_count=("vendor_id", "count"),
        avg_passenger_count=("passenger_count", "mean"),
        avg_trip_distance=("trip_distance", "mean"),
        total_fare_amount=("fare_amount", "sum"),
        avg_trip_duration=("trip_duration_minutes", "mean"),
    ).reset_index()
    summary.to_csv(summary_csv, index=False)
    print(f"[INFO] Processed data with pandas.  Cleaned file: {cleaned_csv}, summary file: {summary_csv}")


def process_without_pandas(input_csv: str, cleaned_csv: str, summary_csv: str) -> None:
    """Process the CSV using only builtâ€‘in Python modules.

    This fallback implementation reads the CSV line by line, filters
    invalid rows, computes trip durations and aggregates metrics in
    dictionaries.  Although slower than pandas, it avoids external
    dependencies.
    """
    os.makedirs(os.path.dirname(cleaned_csv), exist_ok=True)
    os.makedirs(os.path.dirname(summary_csv), exist_ok=True)
    summary: Dict[Tuple[datetime.date, int], Dict[str, float]] = defaultdict(lambda: {
        "trips_count": 0,
        "total_passenger_count": 0.0,
        "total_trip_distance": 0.0,
        "total_fare_amount": 0.0,
        "total_duration": 0.0,
    })
    with open(input_csv, newline="", encoding="utf-8") as infile, open(cleaned_csv, "w", newline="", encoding="utf-8") as outfile:
        reader = csv.DictReader(infile)
        fieldnames = reader.fieldnames + ["trip_duration_minutes"] if reader.fieldnames else []
        writer = csv.DictWriter(outfile, fieldnames=fieldnames)
        writer.writeheader()
        for row in reader:
            try:
                pickup = datetime.datetime.fromisoformat(row["tpep_pickup_datetime"])
                dropoff = datetime.datetime.fromisoformat(row["tpep_dropoff_datetime"])
                passenger_count = int(float(row["passenger_count"]))
                trip_distance = float(row["trip_distance"])
                fare_amount = float(row["fare_amount"])
                total_amount = float(row["total_amount"])
            except Exception:
                continue  # skip malformed rows
            if trip_distance <= 0 or fare_amount < 0:
                continue
            duration = (dropoff - pickup).total_seconds() / 60.0
            # Write cleaned row with duration
            row["trip_duration_minutes"] = f"{duration:.2f}"
            writer.writerow(row)
            # Update summary metrics
            key = (pickup.date(), int(row["vendor_id"]))
            metrics = summary[key]
            metrics["trips_count"] += 1
            metrics["total_passenger_count"] += passenger_count
            metrics["total_trip_distance"] += trip_distance
            metrics["total_fare_amount"] += fare_amount
            metrics["total_duration"] += duration
    # Write summary CSV
    with open(summary_csv, "w", newline="", encoding="utf-8") as sfile:
        writer = csv.writer(sfile)
        writer.writerow([
            "pickup_date",
            "vendor_id",
            "trips_count",
            "avg_passenger_count",
            "avg_trip_distance",
            "total_fare_amount",
            "avg_trip_duration",
        ])
        for (pickup_date, vendor_id), metrics in sorted(summary.items()):
            count = metrics["trips_count"]
            writer.writerow([
                pickup_date,
                vendor_id,
                count,
                metrics["total_passenger_count"] / count if count else 0,
                metrics["total_trip_distance"] / count if count else 0,
                metrics["total_fare_amount"],
                metrics["total_duration"] / count if count else 0,
            ])
    print(f"[INFO] Processed data without pandas.  Cleaned file: {cleaned_csv}, summary file: {summary_csv}")


def main(args: argparse.Namespace) -> None:
    input_csv = args.input
    cleaned_csv = os.path.join("data", "processed", "cleaned_trips.csv")
    summary_csv = os.path.join("data", "processed", "trip_summary.csv")
    pd = try_import_pandas()
    if pd is not None:
        process_with_pandas(input_csv, cleaned_csv, summary_csv)
    else:
        process_without_pandas(input_csv, cleaned_csv, summary_csv)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Clean and aggregate taxi trip data.")
    parser.add_argument(
        "--input",
        type=str,
        default="data/raw/yellow_tripdata_2025-01.csv",
        help="Path to the input CSV file",
    )
    args = parser.parse_args()
    main(args)